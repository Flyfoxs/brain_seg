{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-22 18:41:41,519 util_log.py[153] INFO Start the program at:amax7, 127.0.1.1, with:Load module\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File_cache: Adjust notebook work fold to:/share/felix/pj/brain_seg/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from file_cache import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks.hooks import *\n",
    "\n",
    "gc.collect()\n",
    "def unet_learner( arch:Callable, pretrained:bool=True, blur_final:bool=True,\n",
    "                 norm_type:Optional[NormType]=NormType, split_on:Optional[SplitFuncOrIdxList]=None, blur:bool=False,\n",
    "                 self_attention:bool=False, y_range:Optional[Tuple[float,float]]=None, last_cross:bool=True,\n",
    "                 bottle:bool=False, cut:Union[int,Callable]=None,\n",
    "                 n_classes=2, img_size = (224,224),\n",
    "                 **learn_kwargs:Any)->Learner:\n",
    "    \"Build Unet learner from `data` and `arch`.\"\n",
    "    \"blur: do maxpolling or not\"\n",
    "    body = create_body(arch, pretrained, cut)\n",
    "    model = to_device(models.unet.DynamicUnet(body, n_classes=n_classes, img_size=img_size, blur=blur, blur_final=blur_final,\n",
    "          self_attention=self_attention, y_range=y_range, norm_type=norm_type, last_cross=last_cross,\n",
    "          bottle=bottle), 'cuda')\n",
    "    return model\n",
    "\n",
    "# model = unet_learner( models.resnet50, n_classes=2, img_size = (224,224) )\n",
    "\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(torch.rand(10,3,224,224).cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    6334\n",
      "True     1583\n",
      "Name: valid, dtype: int64\n",
      "torch.Size([3, 224, 224]) (224, 224) [0 1]\n",
      "torch.Size([3, 224, 224]) (224, 224) [0 1]\n",
      "torch.Size([3, 224, 224]) (224, 224) [0 1]\n",
      "torch.Size([3, 224, 224]) (224, 224) [0 1]\n",
      "torch.Size([3, 224, 224]) (224, 224) [0 1]\n",
      "torch.Size([3, 224, 224]) (224, 224) [0 1]\n",
      "torch.Size([3, 224, 224]) (224, 224) [0 1]\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "class DataSet_lung(Dataset):\n",
    "\n",
    "    def __init__(self, ds_type='train'):\n",
    "        super(DataSet_lung, self).__init__()\n",
    "        self.image_size = 256\n",
    "        df = self.get_df()\n",
    "        #print(df.valid.value_counts())\n",
    "        if ds_type == 'train':\n",
    "            #print(ds_type)\n",
    "            self.df = df.loc[df.valid == False]\n",
    "        elif ds_type == 'valid':\n",
    "            self.df = df.loc[df.valid == True]\n",
    "        \n",
    "        self.transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                             ])\n",
    "\n",
    "            \n",
    "    @lru_cache()\n",
    "    def get_df(self):\n",
    "        root = '/home/felix/pj/lung_detectron/data/lung/unet_v9'\n",
    "        file_list = glob(f'{root}/images/*.*')\n",
    "        df = pd.DataFrame({'img':file_list})\n",
    "        df['valid'] = False\n",
    "        total = len(df)\n",
    "        df['valid'].iloc[:total//5] = True\n",
    "        print(df.valid.value_counts())\n",
    "        def get_label_file(file):\n",
    "            file = file.replace('.png', '_P.png')\n",
    "            file = file.replace('images', 'labels')\n",
    "            return file\n",
    "        df['label'] = df.img.apply(lambda val: get_label_file(val))\n",
    "        return df.sample(frac=0.05)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = cv2.imread(self.df.img.iloc[index])\n",
    "        img = cv2.resize(img,(224, 224))\n",
    "        \n",
    "        label = cv2.imread(self.df.label.iloc[index])[:,:,0]\n",
    "        label =  cv2.resize(label, (224,224)).astype(int)\n",
    "        #label = np.stack([ np.where(label==i, 1, 0) for i in range(2)])\n",
    "        return  self.transforms(img ) ,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "for sn, (a, b) in enumerate(DataSet_lung()):\n",
    "    print(a.shape, b.shape, np.unique(b))\n",
    "    if sn> 5: break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-22 18:41:59,552 distrib_data_parallel.py[220] INFO GPU available: True, used: True\n",
      "2020-05-22 18:41:59,553 distrib_data_parallel.py[268] INFO VISIBLE GPUS: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    6334\n",
      "True     1583\n",
      "Name: valid, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation sanity check', layout=Layout(flex='2'), max=5.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': tensor(0.5130, device='cuda:0')}\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec11e057d6e42d3b914e7a827d30472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    6334\n",
      "True     1583\n",
      "Name: valid, dtype: int64\n",
      "False    6334\n",
      "True     1583\n",
      "Name: valid, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=42.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': tensor(0.0706, device='cuda:0')}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=42.0, style=Pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': tensor(0.0389, device='cuda:0')}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class BrainModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BrainModel, self).__init__()\n",
    "        self.unet =  unet_learner( models.resnet50, n_classes=2, img_size = (224,224) ) \n",
    "\n",
    "    def forward(self, x):\n",
    "        # called with self(x)\n",
    "        #print(x.shape)\n",
    "        return self.unet(x)\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        # REQUIRED\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        \n",
    "        #print(y_hat.shape, y.shape, loss)\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        # OPTIONAL\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        return {'val_loss': F.cross_entropy(y_hat, y)}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # OPTIONAL\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        tensorboard_logs = {'val_loss': avg_loss}\n",
    "        print({'val_loss': avg_loss})\n",
    "        return {'val_loss': avg_loss, 'log': tensorboard_logs}\n",
    "\n",
    "    def test_step(self, batch, batch_nb):\n",
    "        # OPTIONAL\n",
    "        print('test_step')\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        return {'test_loss': F.cross_entropy(y_hat, y)}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        # OPTIONAL\n",
    "        print('test_epoch_end')\n",
    "        avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        logs = {'test_loss': avg_loss}\n",
    "        return {'test_loss': avg_loss, 'log': logs, 'progress_bar': logs}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # REQUIRED\n",
    "        # can return multiple optimizers and learning_rate schedulers\n",
    "        # (LBFGS it is automatically supported, no need for closure function)\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.0002)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # REQUIRED\n",
    "        return DataLoader(DataSet_lung('train'), batch_size=8)\n",
    "        #return DataLoader(MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor()), batch_size=32)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        return DataLoader(DataSet_lung('valid'), batch_size=2)\n",
    "        ##return DataLoader(MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor()), batch_size=32)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        return DataLoader(DataSet_lung('valid'), batch_size=2)\n",
    "        #return DataLoader(MNIST(os.getcwd(), train=False, download=True, transform=transforms.ToTensor()), batch_size=32)\n",
    "        \n",
    "        \n",
    "brain_model = BrainModel()\n",
    "\n",
    "# most basic trainer, uses good defaults (1 gpu)\n",
    "trainer = pl.Trainer(gpus=1,\n",
    "                     max_epochs=2,\n",
    "                     weights_summary=None)    \n",
    "trainer.fit(brain_model)  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
